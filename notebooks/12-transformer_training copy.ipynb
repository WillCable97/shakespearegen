{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset tiny_shakespeare (C:/Users/willi/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60a893c97854b938908ae0a46c22dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 79, 512)\n",
      "(64, 79, 512)\n",
      "(64, 79, 512)\n",
      "(64, 79, 512)\n",
      "(64, 79, 512)\n",
      "(64, 79, 512)\n",
      "(64, 79)\n",
      "(64, 79, 512)\n",
      "(64, 79)\n",
      "(64, 79, 11913)\n"
     ]
    }
   ],
   "source": [
    "%run 11-single_embedding_transformer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 79)\n",
      "(64, 79)\n"
     ]
    }
   ],
   "source": [
    "print(tf.convert_to_tensor(input).shape)\n",
    "print(main_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(64, 79), dtype=tf.int32, name=None), TensorSpec(shape=(64, 79), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(batched_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 120s 3s/step - loss: 9.3841 - masked_accuracy: 9.6067e-05\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 100s 3s/step - loss: 9.2950 - masked_accuracy: 0.0067\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 102s 3s/step - loss: 9.1439 - masked_accuracy: 0.0261\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 100s 3s/step - loss: 8.9481 - masked_accuracy: 0.0312\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 100s 3s/step - loss: 8.6967 - masked_accuracy: 0.0314\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 98s 3s/step - loss: 8.3959 - masked_accuracy: 0.0314\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 98s 3s/step - loss: 8.0659 - masked_accuracy: 0.0314\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 98s 3s/step - loss: 7.7322 - masked_accuracy: 0.0314\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 98s 3s/step - loss: 7.4219 - masked_accuracy: 0.0314\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 99s 3s/step - loss: 7.1599 - masked_accuracy: 0.0314\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 99s 3s/step - loss: 6.9645 - masked_accuracy: 0.0314\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 97s 3s/step - loss: 6.8428 - masked_accuracy: 0.0314\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 98s 3s/step - loss: 6.7851 - masked_accuracy: 0.0314\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 98s 3s/step - loss: 6.7558 - masked_accuracy: 0.0329\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 99s 3s/step - loss: 6.7046 - masked_accuracy: 0.0359\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 101s 3s/step - loss: 6.6506 - masked_accuracy: 0.0422\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 103s 3s/step - loss: 6.5859 - masked_accuracy: 0.0488\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 123s 3s/step - loss: 6.5092 - masked_accuracy: 0.0575\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 101s 3s/step - loss: 6.4254 - masked_accuracy: 0.0674\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 104s 3s/step - loss: 6.3396 - masked_accuracy: 0.0746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bd8ba8b5b0>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(batched_dataset,\n",
    "                epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_string = \"Romeo: he went\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_tokenizer = data_object.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104, 20, 1301]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = used_tokenizer.texts_to_sequences([starting_string])[0]\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_token_list = [encoded_input]\n",
    "output_generated = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104, 20, 1301, 2, 4, 23, 8, 91, 2, 4, 23, 8, 91, 2, 4, 23, 8, 91, 2, 4, 23, 8, 91, 2, 4, 23, 8, 91, 2, 1, 91, 2, 1, 91, 2, 4, 23, 8, 91, 2, 4, 23, 8, 91, 2, 1, 91, 2, 1, 91, 2, 1, 91, 5, 1, 91, 5, 1, 91, 5, 1, 91, 2, 1, 91, 2, 1, 91, 2, 1, 91, 2, 1, 91, 5, 1, 91, 5, 1, 91, 5, 1, 91, 5, 1, 91, 5, 1, 91, 2, 1, 91, 3, 1, 91, 2, 1, 91, 5, 1, 91, 2, 1]]\n",
      " and i have a man and i have a man and i have a man and i have a man and i have a man and the man and the man and i have a man and i have a man and the man and the man and the man of the man of the man of the man and the man and the man and the man and the man of the man of the man of the man of the man of the man and the man to the man and the man of the man and the\n"
     ]
    }
   ],
   "source": [
    "print(inner_token_list)\n",
    "print(output_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    inner_input = tf.convert_to_tensor(inner_token_list)\n",
    "    predictions  = transformer(inner_input)[:, -1:, :]\n",
    "    predicted_id = tf.argmax(predictions, axis=-1)\n",
    "    token = predicted_id.numpy()[0][0]\n",
    "    text = used_tokenizer.index_word[token]\n",
    "    output_generated += (' ' + text)\n",
    "    inner_token_list[0].append(token)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
       "array([[ 104,   20, 1301,    3,  587,    2,   67,   26,   18,    8,   91,\n",
       "          13,    8,   91,    2,    8,   91,   11,    8,  309,    2,    8,\n",
       "         309,   13,    8,  309,   13]])>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_input = tf.convert_to_tensor(inner_token_list) \n",
    "inner_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "predictions  = transformer(inner_input)[:, -1:, :]\n",
    "predicted_id = tf.argmax(predictions, axis=-1)\n",
    "token = predicted_id.numpy()[0][0]\n",
    "text = used_tokenizer.index_word[token]\n",
    "output_generated += (' ' + text)\n",
    "inner_token_list[0].append(token)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 11913), dtype=float32, numpy=\n",
       "array([[[-14.466389 ,   3.3970423,   5.709853 , ..., -14.614429 ,\n",
       "         -14.58085  , -14.690559 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights('./transformer_v1/transformer_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'positional_embedding_15' (type PositionalEmbedding).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: transformer_4/decoder_9/positional_embedding_15/strided_slice/\n\nCall arguments received by layer 'positional_embedding_15' (type PositionalEmbedding):\n  • x=tf.Tensor(shape=(3,), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#inner_input = tf.transpose(working_input.stack())\u001b[39;00m\n\u001b[0;32m      2\u001b[0m inner_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(inner_token_list) \n\u001b[1;32m----> 4\u001b[0m predictions  \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:, :]\n\u001b[0;32m      5\u001b[0m predicted_id \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m token \u001b[38;5;241m=\u001b[39m predicted_id\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\willi\\Anaconda3\\envs\\analytics\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21332\\938784600.py:20\u001b[0m, in \u001b[0;36mTransformer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     16\u001b[0m x  \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#context = self.encoder(context)  # (batch_size, context_len, d_model)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, target_len, d_model)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Final linear layer output.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(x)  \u001b[38;5;66;03m# (batch_size, target_len, target_vocab_size)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21332\\2495754611.py:21\u001b[0m, in \u001b[0;36mDecoder.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;66;03m# `x` is token-IDs shape (batch, target_seq_len)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, target_seq_len, d_model)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     25\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21332\\2121223993.py:9\u001b[0m, in \u001b[0;36mPositionalEmbedding.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m#this is for baches\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_layer(x)\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msqrt(tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth, tf\u001b[38;5;241m.\u001b[39mfloat32)) \u001b[38;5;66;03m#not sure\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'positional_embedding_15' (type PositionalEmbedding).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: transformer_4/decoder_9/positional_embedding_15/strided_slice/\n\nCall arguments received by layer 'positional_embedding_15' (type PositionalEmbedding):\n  • x=tf.Tensor(shape=(3,), dtype=int32)"
     ]
    }
   ],
   "source": [
    "#inner_input = tf.transpose(working_input.stack())\n",
    "inner_input = tf.convert_to_tensor(inner_token_list) \n",
    "\n",
    "predictions  = transformer(inner_input)[:, -1:, :]\n",
    "predicted_id = tf.argmax(predictions, axis=-1)\n",
    "token = predicted_id.numpy()[0][0]\n",
    "text = used_tokenizer.index_word[token]\n",
    "#working_input.concat(3)\n",
    "\n",
    "#generated_o+=text\n",
    "#output_array = working_input.write(my_iter_obj, predicted_id[0])\n",
    "\n",
    "#my_iter_obj+=1\n",
    "\n",
    "print(text)\n",
    "print(predicted_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  87  248  143   34  962  145  609  127   16  106   35  106  106   87\n",
      "  248    7   41   35 1228  351    3  192   65    3 3678   35 1228 1228\n",
      "   87  248   87    7   92 1052  214   11 2085  544    3    1  281   35\n",
      "   34 2333   34 2333   87  248   67   78  474   26    2  369   23 1308\n",
      "   53   37  162 2086  646    8 3679   35   33   50 4648 1013   67   15\n",
      "   18  167  154  154  149  248   72  226   46], shape=(79,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for batch in batched_dataset:\n",
    "    print(batch[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_encoded_input = input_to_tensor = tf.convert_to_tensor(encoded_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 104,   20, 1301])>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_o = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner_input = tf.transpose(working_input.stack())\n",
    "\n",
    "\n",
    "predictions  = transformer(inner_input)[:, -1:, :]\n",
    "predicted_id = tf.argmax(predictions, axis=-1)\n",
    "token = predicted_id.numpy()[0][0]\n",
    "text = used_tokenizer.index_word[token]\n",
    "working_input.concat(3)\n",
    "\n",
    "generated_o+=text\n",
    "output_array = working_input.write(my_iter_obj, predicted_id[0])\n",
    "\n",
    "my_iter_obj+=1\n",
    "\n",
    "print(text)\n",
    "print(predicted_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x1bd8785d9d0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_input = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "working_input.write(0,tf.cast(tensor_encoded_input, dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_iter_obj = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000001BD878B6B80>\n"
     ]
    }
   ],
   "source": [
    "print(generated_o)\n",
    "print(working_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[ 104,   20, 1301]], dtype=int64)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_input = working_input.stack()#tf.transpose(working_input.stack())\n",
    "inner_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shape for value ((1,)), expected ((3,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m working_input\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     10\u001b[0m generated_o\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mtext\n\u001b[1;32m---> 11\u001b[0m output_array \u001b[38;5;241m=\u001b[39m \u001b[43mworking_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_iter_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_id\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m my_iter_obj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[1;32mc:\\Users\\willi\\Anaconda3\\envs\\analytics\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:288\u001b[0m, in \u001b[0;36mshould_use_result.<locals>.decorated.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _add_should_use_warning(fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    289\u001b[0m                                  warn_in_eager\u001b[38;5;241m=\u001b[39mwarn_in_eager,\n\u001b[0;32m    290\u001b[0m                                  error_in_function\u001b[38;5;241m=\u001b[39merror_in_function)\n",
      "File \u001b[1;32mc:\\Users\\willi\\Anaconda3\\envs\\analytics\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:1188\u001b[0m, in \u001b[0;36mTensorArray.write\u001b[1;34m(self, index, value, name)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;129m@tf_should_use\u001b[39m\u001b[38;5;241m.\u001b[39mshould_use_result(warn_in_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, index, value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Write `value` into index `index` of the TensorArray.\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;124;03m    ValueError: if there are more writers than specified.\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_implementation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\Anaconda3\\envs\\analytics\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:858\u001b[0m, in \u001b[0;36m_EagerTensorArray.write\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See TensorArray.\"\"\"\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m name  \u001b[38;5;66;03m# not meaningful when executing eagerly.\u001b[39;00m\n\u001b[1;32m--> 858\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent()\n",
      "File \u001b[1;32mc:\\Users\\willi\\Anaconda3\\envs\\analytics\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:847\u001b[0m, in \u001b[0;36m_EagerTensorArray._write\u001b[1;34m(self, index, value)\u001b[0m\n\u001b[0;32m    841\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[0;32m    842\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    843\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorArray dtype is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but Op is trying to write dtype \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    844\u001b[0m       (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype\u001b[38;5;241m.\u001b[39mname, value\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape\u001b[38;5;241m.\u001b[39mis_compatible_with(value\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 847\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shape for value (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), expected (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    848\u001b[0m                    (value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape))\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_shape:\n\u001b[0;32m    851\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape\u001b[38;5;241m.\u001b[39mmerge_with(value\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible shape for value ((1,)), expected ((3,))"
     ]
    }
   ],
   "source": [
    "#inner_input = tf.transpose(working_input.stack())\n",
    "\n",
    "\n",
    "predictions  = transformer(inner_input)[:, -1:, :]\n",
    "predicted_id = tf.argmax(predictions, axis=-1)\n",
    "token = predicted_id.numpy()[0][0]\n",
    "text = used_tokenizer.index_word[token]\n",
    "working_input.concat(3)\n",
    "\n",
    "generated_o+=text\n",
    "output_array = working_input.write(my_iter_obj, predicted_id[0])\n",
    "\n",
    "my_iter_obj+=1\n",
    "\n",
    "print(text)\n",
    "print(predicted_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 11913), dtype=float32, numpy=\n",
       "array([[[-13.653607 ,   3.5102906,   4.55223  , ..., -13.595964 ,\n",
       "         -13.772838 , -13.836386 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions  = transformer(tensor_encoded_input)[:, -1:, :]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[3]], dtype=int64)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_id = tf.argmax(predictions, axis=-1)\n",
    "predicted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mused_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_word\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "text = used_tokenizer.index_word[predicted_id.numpy()]\n",
    "#.lookup(predicted_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
