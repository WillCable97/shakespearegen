{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data object\n",
    "%run 6-transformer_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_object = TransformerDataSet(\"tiny_shakespeare\", 80)\n",
    "\n",
    "\n",
    "file_path_for_text = r\"C:\\Users\\willi\\Desktop\\Data Science Portfolio\\shakespearegen\\data\\raw\\archive\\alllines.txt\"\n",
    "data_object = TransformerDataSetText(file_path_for_text, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length: int, depth: int):\n",
    "    effective_depth = depth / 2\n",
    "    depth_vector = np.repeat(np.arange(effective_depth), 2)\n",
    "    frequency_vector = 1/(10000**((2* depth_vector)/depth))\n",
    "    sequence_vector = np.arange(length)\n",
    "    pos_encoding = sequence_vector.reshape([-1,1]) * frequency_vector.reshape([1,-1])\n",
    "    pos_encoding[:,::2] = np.sin(pos_encoding[:,::2])\n",
    "    pos_encoding[:,1::2] = np.cos(pos_encoding[:,1::2])\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, depth):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(vocab_size, depth, mask_zero=True)\n",
    "        self.positional_func = positional_encoding(vocab_size, depth)\n",
    "    \n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1] #this is for baches\n",
    "        x = self.embedding_layer(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.depth, tf.float32)) #not sure\n",
    "        x = x + self.positional_func[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and labels for purpose of testing in downstream notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are limited to match the batchsize of the actual dataset\n",
    "input, main_labels = data_object.inputs[:64], data_object.outputs[:64]\n",
    "#input, main_labels = data_object.inputs, data_object.outputs\n",
    "vocab_s = data_object.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18887\n"
     ]
    }
   ],
   "source": [
    "print(vocab_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "posit_layer_inst = PositionalEmbedding(vocab_size=vocab_s, depth=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 79, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posit_layer_output = posit_layer_inst(tf.convert_to_tensor(input))\n",
    "posit_layer_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4366288\n"
     ]
    }
   ],
   "source": [
    "print(len(data_object.laoded_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_tensor = tf.convert_to_tensor(data_object.inputs) \n",
    "labels_to_tensor = tf.convert_to_tensor(data_object.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10265, 79)\n",
      "(10265, 79)\n"
     ]
    }
   ],
   "source": [
    "print(input_to_tensor.shape)\n",
    "print(labels_to_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10265, 79])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = tf.data.Dataset.from_tensor_slices(input_to_tensor)\n",
    "label_dataset = tf.data.Dataset.from_tensor_slices(labels_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_main_dataset = tf.data.Dataset.zip((input_dataset, label_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ZipDataset element_spec=(TensorSpec(shape=(79,), dtype=tf.int32, name=None), TensorSpec(shape=(79,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dataset = tf_main_dataset.batch(128, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
