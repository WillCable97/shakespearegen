from src.data.TextToToken.TextToToken import TextToToken

class TextToToken(TextToToken):
    """
        Generalised wrapper for handling the tokenizing of data inputs
    """

    def init_with_input(self, input: list):
        """
            Will create tokens on original text
            Will evaluate vocab size here
        """

    def tokenise(self, input: list):
        """
            Given another input, will convert to tokens
        """
    
    def detokenise(self, input: list) -> list:
        """
            Will take lit of takens and convert to string
        """

